{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e161888b-f9ff-4494-a7ae-9115d341ff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from src.category_tree.category_tree import CategoryTree\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763c45c7-1b6b-432f-bc17-6db83564e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00909c4c-012e-4a3c-9ee9-fe0fa8e282a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_ID_COL = \"cat_id\"\n",
    "TITLE_COL = \"source_name\"\n",
    "\n",
    "TITLE_MODEL_COL = \"text\"\n",
    "CAT_ID_MODEL_COL = \"label\"\n",
    "PART_TYPE_COL = \"part_type\"\n",
    "PART_COL = \"part\"\n",
    "\n",
    "DATASET_PATH = \"../data/dataset_v1/dataset_for_experiments.parquet\"\n",
    "CAT_TREE_PATH = \"../data/category_tree.csv\"\n",
    "\n",
    "MODEL = \"cointegrated/rubert-tiny2\"\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f845df4-072a-4ad0-95de-ec2e2a21c343",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bba43423-0935-40f1-8d44-977aaff1e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree = CategoryTree(category_tree_path=LOCAL_CAT_TREE_PATH)\n",
    "df = pd.read_parquet(LOCAL_DATASET_PATH)\n",
    "\n",
    "df = df.rename(columns={TITLE_COL:TITLE_MODEL_COL, CAT_ID_COL:CAT_ID_MODEL_COL})\n",
    "df[CAT_ID_MODEL_COL] = category_tree.label_encoder.transform(df[CAT_ID_MODEL_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8efa10f-3496-4abe-a37d-2f065b086e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>part_type</th>\n",
       "      <th>part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сетевой кабель, патч корд Rj45 5 метров CAT5E,...</td>\n",
       "      <td>627</td>\n",
       "      <td>is</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Фильтр-заглушка сливного насоса стиральной маш...</td>\n",
       "      <td>649</td>\n",
       "      <td>is</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Умные часы CheckME Smart CMSKC06SS с калькулят...</td>\n",
       "      <td>38</td>\n",
       "      <td>is</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Силиконовый чехол Mcover для беспроводных науш...</td>\n",
       "      <td>56</td>\n",
       "      <td>is</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Зарядное устройство Panasonic Basic BQ-CC51 + ...</td>\n",
       "      <td>307</td>\n",
       "      <td>is</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label part_type   part\n",
       "0  Сетевой кабель, патч корд Rj45 5 метров CAT5E,...    627        is  train\n",
       "1  Фильтр-заглушка сливного насоса стиральной маш...    649        is  train\n",
       "2  Умные часы CheckME Smart CMSKC06SS с калькулят...     38        is  train\n",
       "3  Силиконовый чехол Mcover для беспроводных науш...     56        is  train\n",
       "4  Зарядное устройство Panasonic Basic BQ-CC51 + ...    307        is  train"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8b213-81f6-459e-a775-6b2a844ba873",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ade5ece1-cf38-43a1-8af7-bcd3987819ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[TITLE_MODEL_COL], truncation=True)\n",
    "\n",
    "def load_experiment_dataset(df: pd.DataFrame):\n",
    "    parts_datasets = {\n",
    "        part: Dataset.from_pandas(\n",
    "            df[df[PART_COL]==part][[TITLE_MODEL_COL, CAT_ID_MODEL_COL]],\n",
    "            split=part\n",
    "        )\n",
    "        for part in [\"train\", \"val\"]\n",
    "    }\n",
    "\n",
    "    dataset = DatasetDict(parts_datasets)\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    return tokenized_dataset\n",
    "\n",
    "def load_full_dataset(df: pd.DataFrame):\n",
    "    dataset = Dataset.from_pandas(df[[TITLE_MODEL_COL, CAT_ID_MODEL_COL]])\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a1842c4-df33-4dce-ad80-229be6b6016e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01d4765883b4e60848fa1b51062f1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/491736 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a034d4437b7c48d390958e779393c540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = load_experiment_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ad826-85bb-43ad-851e-3303e480a624",
   "metadata": {},
   "source": [
    "# Label Smoothing\n",
    "Идея: для каждой вершины размажем вероятность по ее соседям-листьям(должно уменьшать влияние ошибок разметки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e401c18e-a293-4b3b-8175-ce3aaa2df6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Trainer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from functools import partial\n",
    "\n",
    "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, category_tree: CategoryTree, smoothing: float = 0.2, reduction: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.smoothing = smoothing\n",
    "        self.category_tree = category_tree\n",
    "\n",
    "        self.label_encoder = self.category_tree.label_encoder\n",
    "        self.leaf_nodes = set(self.category_tree.leaf_nodes)\n",
    "        self.category_tree_edges = self.category_tree.inverted_edge_dict \n",
    "\n",
    "        self.nearest_neighbors = self._precompute_nearest_neighbors()\n",
    "        \n",
    "        self.loss_fct = CrossEntropyLoss(reduction=reduction)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        num_classes = input.shape[-1]\n",
    "        \n",
    "        true_dist = self._smooth_labels(target=target, num_classes=num_classes)\n",
    "        loss = self.loss_fct(input, true_dist)\n",
    "        return loss\n",
    "\n",
    "    def _smooth_labels(self, target, num_classes):\n",
    "        # Initialize smoothed label distribution\n",
    "        true_dist = torch.zeros(target.size(0), num_classes).to(target.device)\n",
    "\n",
    "        target_inv = self.label_encoder.inverse_transform(target.tolist())\n",
    "        for i, (label, label_inv) in enumerate(zip(target, target_inv)):\n",
    "            # Distribute smoothing factor among nearest neighbors\n",
    "            neighbors = self.nearest_neighbors[label_inv]\n",
    "            neighbors = self.label_encoder.transform(neighbors)\n",
    "\n",
    "            # Set the true label probability\n",
    "            if len(neighbors) == 0:\n",
    "                true_dist[i, label] = 1.0\n",
    "            else:\n",
    "                true_dist[i, label] = 1.0 - self.smoothing\n",
    "                neighbor_prob = self.smoothing / len(neighbors)\n",
    "                true_dist[i, neighbors] = neighbor_prob\n",
    "        \n",
    "        return true_dist\n",
    "\n",
    "    def _precompute_nearest_neighbors(self):\n",
    "        neighbors = dict()\n",
    "        \n",
    "        for label in self.leaf_nodes:\n",
    "            target_parent = self.category_tree_edges[label]\n",
    "            label_neighbors = []\n",
    "            for node, parent in self.category_tree_edges.items():\n",
    "                if parent == target_parent and node != label and node in self.leaf_nodes:\n",
    "                    label_neighbors.append(node)\n",
    "            neighbors[label] = label_neighbors\n",
    "        \n",
    "        return neighbors\n",
    "\n",
    "class LabelSmoothingCrossEntropyLossTrainer(Trainer):\n",
    "    def __init__(self, category_tree: CategoryTree, smoothing: float, reduction: str, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = LabelSmoothingCrossEntropyLoss(category_tree=category_tree, smoothing=smoothing, reduction=reduction)\n",
    "        self.ce_loss = CrossEntropyLoss(reduction=reduction)\n",
    "         \n",
    "    def compute_loss(self, model, inputs, num_items_in_batch=0, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits, labels = outputs.logits, inputs[\"labels\"]\n",
    "        \n",
    "        if model.training:\n",
    "            loss = self.loss_fct(logits, labels)\n",
    "        else:\n",
    "            loss = self.ce_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd10fb3-636c-4253-973e-6d790c5ce0a5",
   "metadata": {},
   "source": [
    "# Обучение модели(train + val)\n",
    "\n",
    "Оценим качество такого подхода на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90afc702-6661-4390-bd46-733b87136234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.transformers_metrics import hierarchical_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1776d-90c4-4f19-8184-b38e7da12540",
   "metadata": {},
   "source": [
    "## 1. Обучение с Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7471aa47-7a59-4adf-80d2-59311392bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3842' max='3842' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3842/3842 08:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hierarchical Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.448400</td>\n",
       "      <td>5.137580</td>\n",
       "      <td>0.288843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.590600</td>\n",
       "      <td>4.564746</td>\n",
       "      <td>0.393297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.922800</td>\n",
       "      <td>4.331824</td>\n",
       "      <td>0.414706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.616800</td>\n",
       "      <td>4.247887</td>\n",
       "      <td>0.423817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>4.116574</td>\n",
       "      <td>0.435737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.353100</td>\n",
       "      <td>4.051841</td>\n",
       "      <td>0.440705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.305400</td>\n",
       "      <td>4.060180</td>\n",
       "      <td>0.442233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3842, training_loss=2.0252213008946147, metrics={'train_runtime': 498.2579, 'train_samples_per_second': 986.911, 'train_steps_per_second': 7.711, 'total_flos': 676148946465600.0, 'train_loss': 2.0252213008946147, 'epoch': 1.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(category_tree.leaf_nodes)\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"label_smoothing_rubert_trainer\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=512,\n",
    "    report_to=\"none\" # disable wandb\n",
    ")\n",
    "\n",
    "trainer = LabelSmoothingCrossEntropyLossTrainer(\n",
    "    model=model,\n",
    "    category_tree=category_tree,\n",
    "    smoothing=0.2,\n",
    "    reduction=\"mean\",\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"val\"],\n",
    "    processing_class=tokenizer, # Automatic DataCollatorWithPadding\n",
    "    compute_metrics=partial(hierarchical_accuracy, category_tree=category_tree.inverted_edge_dict)\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc85bd2-37cc-4d96-9efd-3ecf46a4a1c3",
   "metadata": {},
   "source": [
    "## 2. Обуение без Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fed60dcf-b667-4f78-b03b-55560dfbae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3842' max='3842' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3842/3842 05:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Hierarchical Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.097900</td>\n",
       "      <td>5.958326</td>\n",
       "      <td>0.273530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.072500</td>\n",
       "      <td>5.773002</td>\n",
       "      <td>0.393524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.371600</td>\n",
       "      <td>5.673862</td>\n",
       "      <td>0.423695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.061000</td>\n",
       "      <td>5.765710</td>\n",
       "      <td>0.429899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.888400</td>\n",
       "      <td>5.773645</td>\n",
       "      <td>0.432419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.784800</td>\n",
       "      <td>5.809369</td>\n",
       "      <td>0.434596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.738500</td>\n",
       "      <td>5.849384</td>\n",
       "      <td>0.436265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3842, training_loss=1.4966335822864474, metrics={'train_runtime': 311.3373, 'train_samples_per_second': 1579.432, 'train_steps_per_second': 12.34, 'total_flos': 676148946465600.0, 'train_loss': 1.4966335822864474, 'epoch': 1.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(category_tree.leaf_nodes)\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"rubert_trainer\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=512,\n",
    "    report_to=\"none\" # disable wandb\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"val\"],\n",
    "    processing_class=tokenizer, # Automatic DataCollatorWithPadding\n",
    "    compute_metrics=partial(hierarchical_accuracy, category_tree=category_tree.inverted_edge_dict)\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c362071-97ac-41fb-9cee-6c1e25350a8f",
   "metadata": {},
   "source": [
    "# Обучение модели(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e35497e7-f60c-432f-ae08-916783eca9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0358038592734c47b9f7541b65682d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/614716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = load_full_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d91a5c-71ea-42b9-a21f-d6a03934b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4803' max='4803' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4803/4803 06:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.653600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.956700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.613100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.212700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.184100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4803, training_loss=1.8641801175290833, metrics={'train_runtime': 420.0021, 'train_samples_per_second': 1463.602, 'train_steps_per_second': 11.436, 'total_flos': 866965952696160.0, 'train_loss': 1.8641801175290833, 'epoch': 1.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(category_tree.leaf_nodes)\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"label_smoothing_rubert_full_trainer\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=128,\n",
    "    report_to=\"none\" # disable wandb\n",
    ")\n",
    "\n",
    "trainer = LabelSmoothingCrossEntropyLossTrainer(\n",
    "    model=model,\n",
    "    category_tree=category_tree,\n",
    "    smoothing=0.2,\n",
    "    reduction=\"mean\",\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    processing_class=tokenizer, # Automatic DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163cbef-73e7-4bff-8c18-5b4f3a5f1cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
